{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f42dec9d",
   "metadata": {},
   "source": [
    "# Talk to PDF\n",
    "This is a simple chatbot which can look up a give pdf and answer your questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f74ec2",
   "metadata": {},
   "source": [
    "### Download and install necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ab6154",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install PyPDF2 langchain openai\n",
    "pip install typing-extensions --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04fc9bf",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18b1479",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader # used to extract text from pdf\n",
    "from langchain.text_splitter import CharacterTextSplitter # split text in smaller snippets\n",
    "import os # read API key from environment variables. Not required if you are specifying the key in notebook.\n",
    "import openai # used to access openai api\n",
    "import json # used to create a json to store snippets and embeddings\n",
    "from numpy import dot # used to match user questions with snippets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c56818",
   "metadata": {},
   "source": [
    "### Parameters specifying different variables used in the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0ffd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTRACTED_TEXT_FILE_PATH = \"pdf_text.txt\" # text extracted from pdf\n",
    "EXTRACTED_JSON_PATH = \"extracted.json\" # snippets and embeddings\n",
    "OPENAI_API_KEY = os.environ['OPENAI_API_KEY'] # replace this with your openai api key or store the api key in env\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\" # embedding model used\n",
    "GPT_MODEL = \"gpt-3.5-turbo\" # gpt model used. alternatively you can use gpt-4 or other models.\n",
    "CHUNK_SIZE = 1000 # chunk size to create snippets\n",
    "CHUNK_OVERLAP = 200 # check size to create overlap between snippets\n",
    "CONFIDENCE_SCORE = 0.75 # specify confidence score to filter search results. [0,1] prefered: 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c47ddd",
   "metadata": {},
   "source": [
    "### Helper Function to extract text from pdf\n",
    "The extracted text is saved in a text file - `pdf_text.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915b0f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(file_path: str):\n",
    "    \n",
    "    # Open the PDF file using the specified file_path\n",
    "    reader = PdfReader(file_path)\n",
    "    # Get the total number of pages in the PDF\n",
    "    number_of_pages = len(reader.pages)\n",
    "\n",
    "    # Initialize an empty string to store extracted text\n",
    "    pdf_text = \"\"\n",
    "\n",
    "    # Loop through each page of the PDF\n",
    "    for i in range(number_of_pages):\n",
    "        # Get the i-th page\n",
    "        page = reader.pages[i]\n",
    "        # Extract text from the page and append it to pdf_text\n",
    "        pdf_text += page.extract_text()\n",
    "        # Add a newline after each page's text for readability\n",
    "        pdf_text += \"\\n\"\n",
    "    \n",
    "    # Specify the file path for the new text file\n",
    "    file_path = EXTRACTED_TEXT_FILE_PATH\n",
    "\n",
    "    # Write the content to the text file\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(pdf_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c978bb82",
   "metadata": {},
   "source": [
    "### Helper function to turn text into embeddings\n",
    "This representation allows the computer to work with textual data in a way that is amenable to mathematical operations and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cc2695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(file_path: str):\n",
    "    \n",
    "    # Initialize a list to store text snippets\n",
    "    snippets = []\n",
    "    # Initialize a CharacterTextSplitter with specified settings\n",
    "    text_splitter = CharacterTextSplitter(separator=\"\\n\",\n",
    "                                         chunk_size=CHUNK_SIZE,\n",
    "                                         chunk_overlap=CHUNK_OVERLAP,\n",
    "                                         length_function=len)\n",
    "\n",
    "    # Read the content of the file specified by file_path\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            file_text = file.read()\n",
    "\n",
    "    # Split the text into snippets using the specified settings\n",
    "    snippets = text_splitter.split_text(file_text)\n",
    "    \n",
    "    # Set the OpenAI API key\n",
    "    openai.api_key = OPENAI_API_KEY\n",
    "    \n",
    "    # Request embeddings for the snippets using the specified model\n",
    "    response = openai.Embedding.create(input=snippets,model=EMBEDDING_MODEL)\n",
    "    \n",
    "    # Extract embeddings from the API response\n",
    "    embedding_list = [response_object['embedding'] for response_object in response['data']]\n",
    "\n",
    "    # Create a JSON object containing embeddings and snippets\n",
    "    embedding_json = {\n",
    "        'embeddings': embedding_list,\n",
    "        'snippets': snippets\n",
    "    }\n",
    "    \n",
    "    # Convert the JSON object to a formatted JSON string\n",
    "    json_object = json.dumps(embedding_json, indent=4)\n",
    "\n",
    "    # Write the JSON string to a file specified by EXTRACTED_JSON_PATH\n",
    "    with open(EXTRACTED_JSON_PATH, 'w', encoding=\"utf-8\") as file:\n",
    "        file.write(json_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c821fc9f",
   "metadata": {},
   "source": [
    "### Helper function to read Embedding JSON file\n",
    "Reads `extracted.json` and prepared embedding for chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc35e61f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_embeddings():\n",
    "    \n",
    "    # Open the JSON file containing embeddings and snippets\n",
    "    with open(EXTRACTED_JSON_PATH,'r') as file:\n",
    "        # Load the JSON data into a Python dictionary\n",
    "        embedding_json = json.load(file)\n",
    "        \n",
    "    # Return the embeddings and snippets from the loaded JSON\n",
    "    return embedding_json['embeddings'], embedding_json['snippets']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4dcbb1",
   "metadata": {},
   "source": [
    "### Helper function to create Embedding from User's Question:\n",
    "Output of this function is used to find the right embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669f42a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_question_embedding_creator(question):\n",
    "    \n",
    "    # Request embedding for the provided question using the specified model\n",
    "    response = openai.Embedding.create(input=question,\n",
    "                                  model=EMBEDDING_MODEL)\n",
    "    \n",
    "    # Extract and return the embedding from the API response\n",
    "    return response.data[0]['embedding']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d016c0f",
   "metadata": {},
   "source": [
    "### Helper function to answer user's question. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a1742d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_users_question(user_question):\n",
    "    \n",
    "    try:\n",
    "        # Create an embedding for the user's question\n",
    "        user_question_embedding = user_question_embedding_creator(user_question)\n",
    "    except Exception as e:\n",
    "        # Handle any exception that occurred while using Embedding API.\n",
    "        return f\"An error occurred while creating embedding: {str(e)}\"\n",
    "        \n",
    "    \n",
    "    # Calculate cosine similarities between the user's question embedding and the document embeddings\n",
    "    cosine_similarities = []\n",
    "    for embedding in embeddings:\n",
    "        cosine_similarities.append(dot(user_question_embedding,embedding))\n",
    "\n",
    "    # Pair snippets with their respective cosine similarities and sort them by similarity\n",
    "    scored_snippets = zip(snippets, cosine_similarities)\n",
    "    sorted_snippets = sorted(scored_snippets, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Filter snippets based on a confidence score and select the top 5 results\n",
    "    formatted_top_results = [snipps for snipps, _score in sorted_snippets if _score > CONFIDENCE_SCORE]\n",
    "    if len(formatted_top_results) > 5:\n",
    "        formatted_top_results = formatted_top_results[:5]\n",
    "        \n",
    "    # Create the chatbot system using pdf_description provided by the user.\n",
    "    chatbot_system = f\"\"\"You are provided with SEARCH RESULTS from a pdf. This pdf is a {pdf_description}. You need to generate answer to the user's question based on the given SEARCH RESULTS. SEARCH RESULTS as a python list. SEARCH RESULTS and USER's QUESTION are delimited by ``` \\n If there is no information available, or question is irrelevent respond with - \"Sorry! I can't help you.\" \"\"\"\n",
    "    \n",
    "    # Create the prompt using results and user's question.\n",
    "    prompt = f\"\"\"\\\n",
    "    SEARCH RESULTS:\n",
    "    ```\n",
    "    {formatted_top_results}\n",
    "    ```\n",
    "    USER'S QUESTION:\n",
    "    ```\n",
    "    {user_question}\n",
    "    ```\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Prepare the chat conversation and use GPT model for generating a response\n",
    "    messages = [{'role':'system', 'content':chatbot_system},\n",
    "                {'role':'user', 'content':prompt}]\n",
    "    \n",
    "    try:\n",
    "        completion = openai.ChatCompletion.create(model=GPT_MODEL,\n",
    "                                             messages=messages,\n",
    "                                             temperature=0,\n",
    "                                             stream=False)\n",
    "    except Exception as e:\n",
    "        # Handle exception while communicating with ChatCompletion API\n",
    "        return f\"An error occurred with chatbot: {str(e)}\"\n",
    "        \n",
    "    # Return the chatbot response.\n",
    "    return completion['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b36eea",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145b0cf4",
   "metadata": {},
   "source": [
    "## Start Here\n",
    "Specify the path to pdf below and run all the cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7d6b52",
   "metadata": {},
   "source": [
    "**Specify the path to pdf to be extracted.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9925b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_FILE_PATH = \"chatgpt_unsesco.pdf.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23899f6",
   "metadata": {},
   "source": [
    "**Converting pdf to text file.**\n",
    "> âš ï¸ **Comment it only when needed.**\n",
    "> You need to extract text only once.\n",
    "\n",
    "This is a helper function to extract text from pdf specified above.\n",
    "\n",
    "Add `#` to the beginning of this function after extracting text from the pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cc31ef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "extract_text_from_pdf(PDF_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf74411",
   "metadata": {},
   "source": [
    "**Creating embeddings from text file.**\n",
    "\n",
    "> âš ï¸ **Use it only when needed**\n",
    "> Billed Function. Required only, once per pdf file.\n",
    "\n",
    "`create_embeddings` function is billed, it uses OpenAI's APIs to create embeddings, use it only when required. Comment it after creating embeddings from the pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2da4152",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_embeddings(EXTRACTED_TEXT_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee02280",
   "metadata": {},
   "source": [
    "**Prepare Embeddings**\n",
    "\n",
    "This reads the embeddings from the json file and stores them for chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64eadb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings, snippets = get_embeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7450cd",
   "metadata": {},
   "source": [
    "## Describe your pdf.\n",
    "Please provide a detailed explanation of the content and purpose of your PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd02be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_description = \"\"\"UNSESCO Guidelines on ChatGPT and Generative AI\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827370bb",
   "metadata": {},
   "source": [
    "## Chatbot\n",
    "This is the logic for chatbot.\n",
    "\n",
    "**To exit leave user input blank and hit enter.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5c6a8d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Start an infinite loop, allowing the user to ask questions\n",
    "while True:\n",
    "    \n",
    "    # Prompt the user to input a question\n",
    "    print(\"ðŸ‘¤USER:\")\n",
    "    \n",
    "    # Read the user's question from the console\n",
    "    user_question = input(\"\")\n",
    "    \n",
    "    # Print a separator for readability\n",
    "    print(\"----------------------\")\n",
    "    \n",
    "    # Check if the user entered an empty question\n",
    "    if user_question ==\"\":\n",
    "        \n",
    "        # If the user entered an empty question, exit the loop\n",
    "        break\n",
    "    else:\n",
    "        \n",
    "        # If the user entered a question, proceed to generate a response\n",
    "        print(\"ðŸ¤– BOT:\")\n",
    "        \n",
    "        # Call the function to generate an answer based on the user's question\n",
    "        # and print the bot's response\n",
    "        print(answer_users_question(user_question=user_question))\n",
    "        \n",
    "        # Print a separator for readability\n",
    "        print(\"----------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
